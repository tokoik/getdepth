#version 430 core

// ワークグループのサイズ
layout (local_size_x = 16, local_size_y = 20) in;

// 入力
layout (binding = 0, r16ui) readonly uniform uimage2D depth;

// イメージのサイズ - 1
const ivec2 ds = imageSize(depth) - 1;

// 出力
layout (binding = 1, rgba32f) writeonly uniform image2D point;
layout (binding = 2, std430) writeonly buffer Uvmap
{
  vec2 uvmap[];
};

// フィルタのサイズ
const ivec2 filterSize = ivec2(5, 5);

// フィルタの中心位置
const ivec2 filterOffset = filterSize / 2;

// 一度に処理する領域のサイズ
const ivec2 tileSize = ivec2(gl_WorkGroupSize) - ivec2(0, filterOffset.y * 2);

// 近傍を含む領域のサイズ
const ivec2 neighborhoodSize = tileSize + filterOffset * 2;

// バイラテラルフィルタの距離に対する重みの Shader Storage Buffer Object
layout (binding = 3, std430) readonly buffer Weight
{
  float columnWeight[filterSize.y];
  float rowWeight[filterSize.x];
  float variance;
};

// デプスセンサのカメラパラメータ
uniform vec2 dpp, df;

// カラーセンサのカメラパラメータ
uniform vec2 cpp, cf;

// RealSense のカラーセンサに対するデプスセンサの外部パラメータ
uniform mat3 extRotation;
uniform vec3 extTranslation;

// 深度の最大値
uniform float maxDepth = 5000.0;

// 処理する領域の近傍を含めたコピー
shared float pixel[neighborhoodSize.y][neighborhoodSize.x];
shared float row[neighborhoodSize.y][tileSize.x]; 

// インデックスがイメージの領域から外れないようにする
ivec2 clampLocation(ivec2 xy)
{
  return clamp(xy, ivec2(0), ds);
}

// 他のスレッドの共有メモリへのアクセス完了と他のワークグループの処理完了を待つ
void retirePhase()
{
  memoryBarrierShared();
  barrier();
}

void main(void)
{
  // ワークグループが処理する領域の基準位置
  const ivec2 tile_xy = ivec2(gl_WorkGroupID);

  // スレッドが処理する画素のワークグループにおける相対位置
  const ivec2 thread_xy = ivec2(gl_LocalInvocationID);

  // 書き込み先のイメージ上の画素位置
  const ivec2 dst_xy = tile_xy * tileSize + thread_xy;

  // 読み込み元のイメージ上の画素位置（上下反転＋
  const ivec2 src_xy = ivec2(dst_xy.x, ds.y - dst_xy.y + filterOffset.y);

  // スレッドが処理する画素位置
  const uint x = thread_xy.x;
  const uint y = thread_xy.y;

  // 処理する領域をコピーする
  for (int i = 0; i < neighborhoodSize.x; i += tileSize.x)
  {
    if (x + i < neighborhoodSize.x)
    {
      // 上限を反転した位置から読み込む
      const ivec2 read_at = clampLocation(ivec2(src_xy.x + i - filterOffset.x, src_xy.y));
      pixel[y][x + i] = float(imageLoad(depth, read_at).r);
    }
  }

  // 他のスレッドの共有メモリへのアクセス完了と他のワークグループの処理完了を待つ
  retirePhase();

  // 対象画素の値を基準値とする
  float base = pixel[y][x + filterOffset.x];

  // 対象画素の値とその重みのペアを作る
  vec2 csum = vec2(0.0);

  // 列方向の重み付け和を求める
  for(int i = 0; i < filterSize.x; ++i)
  {
    const float c = pixel[y][x + i];
    if (c == 0.0) continue;
    const float d = c - base;
    const float e = exp(-0.5 * d * d / variance) * rowWeight[i];
    csum += vec2(c * e, e);
  }

  // デプス値を取り出す
  //row[y][x] = mix(csum.r / csum.g, 0.0, step(0.0, -csum.r));
  row[y][x] = csum.r > 0.0 ? csum.r / csum.g : 0.0;

  // 他のスレッドの共有メモリへのアクセス完了と他のワークグループの処理完了を待つ
  retirePhase();

  if (y < tileSize.y)
  {
    // 対象画素の値とその重みのペアを作る
    vec2 csum = vec2(0.0);

    // 行方向の重み付け和を求める
    for (int j = 0; j < filterSize.y; ++j)
    {
      const float c = row[y + j][x];
      if (c == 0.0) continue;
      const float d = c - base;
      const float e = exp(-0.5 * d * d / variance) * columnWeight[j];
      csum += vec2(c * e, e);
    }

    // デプス値を取り出す
    //const float z = 0.001 * mix(csum.r / csum.g, maxDepth, step(0.0, -csum.r));
    const float z = 0.001 * (csum.g > 0.0 ? csum.r / csum.g : maxDepth);

    // 画素のスクリーン座標 (D415/D435 はデプスセンサのゆがみ補正をする必要がない)
    const vec2 dp = (src_xy - dpp) / df;

    // デプス値からカメラ座標値を求める
    const vec3 p = vec3(dp * z, z);

    // カメラ座標を出力する
    imageStore(point, dst_xy, vec4(p.x, -p.yz, 1.0));

    // カメラ座標からテクスチャ座標を求める
    const vec3 t = extRotation * p + extTranslation;

    // テクスチャ座標を出力する
    uvmap[dst_xy.y * imageSize(depth).x + dst_xy.x] = cf * t.xy / t.z + cpp;
  }
}
